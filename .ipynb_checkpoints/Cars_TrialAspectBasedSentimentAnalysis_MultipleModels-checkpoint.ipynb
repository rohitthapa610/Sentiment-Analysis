{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import *\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "source_word2idx = {}\n",
    "target_word2idx = {}\n",
    "source_data = []\n",
    "source_loc_data = []\n",
    "target_data = []\n",
    "target_label = []\n",
    "\n",
    "final_list = []\n",
    "max_length = 0\n",
    "\n",
    "def read_data(file):\n",
    "    data_train_1 = pd.read_csv(file)\n",
    "    return data_train_1\n",
    "\n",
    "def read_and_process_data(data_train_1, sourceWord2idx, targetWord2idx):\n",
    "    global source_word2idx\n",
    "    global target_word2idx\n",
    "    source_word2idx = sourceWord2idx\n",
    "    target_word2idx = targetWord2idx\n",
    "    #parse_data(data_train_1)\n",
    "    #create_vocab(data_train_1)\n",
    "    data_train_1.apply(prepare_data,axis = 1)\n",
    "    return source_data, source_loc_data, target_data, target_label, max_length\n",
    "\n",
    "\n",
    "def split_data(data_train_1, train_size, test_size):\n",
    "    size = data_train_1.shape[0]\n",
    "    training_rows = math.ceil((train_size/100)*size)\n",
    "    testing_rows = size - training_rows\n",
    "    train_data = data_train_1.iloc[0:training_rows]\n",
    "    test_data = data_train_1.iloc[training_rows:]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def custom_tokenize(text):\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    words = [word for word in tokens if word.isalnum()]\n",
    "    return words\n",
    "\n",
    "\n",
    "def parse_data(data_train_1):\n",
    "    data_train_1[' text'] = data_train_1[' text'].apply(lambda x: x.replace('[comma]',',').lower())\n",
    "    data_train_1[' text'] = data_train_1[' text'].apply(custom_tokenize)\n",
    "    data_train_1[' aspect_term'] = data_train_1[' aspect_term'].apply(lambda x: x.lower())\n",
    "    data_train_1[' aspect_term'] = data_train_1[' aspect_term'].apply(custom_tokenize)\n",
    "    data_train_1[' aspect_term'] = data_train_1[' aspect_term'].apply(lambda x:\" \".join(x))\n",
    "    return data_train_1\n",
    "\n",
    "\n",
    "def prepare_data(row):\n",
    "    global max_length\n",
    "    global source_word2idx\n",
    "    global target_word2idx\n",
    "    m = [source_word2idx[id] for id in row[' text']]\n",
    "    if len(m) == 2602:\n",
    "        print(row[' text'])\n",
    "    if len(m) > max_length:\n",
    "        max_length = len(m)\n",
    "    source_data.append(m)\n",
    "    t = [target_word2idx[row[' aspect_term']]]\n",
    "    target_data.append(t)\n",
    "    target_label.append(row[' class'])\n",
    "    g = get_pos(row)\n",
    "    datab = []\n",
    "    datab.append(m)\n",
    "    datab.append(g)\n",
    "    datab.append(t)\n",
    "    final_list.append(datab)\n",
    "\n",
    "\n",
    "def get_pos_old(row):\n",
    "    index = []\n",
    "    s_len = len(row[' text'])-1\n",
    "    p = row[' text'].copy()\n",
    "    #print('%s in %s: '%(row[' aspect_term'],row[' text']))\n",
    "    aspects = row[' aspect_term'].split(' ')\n",
    "    for aspect in aspects:\n",
    "        try:\n",
    "            if len(aspects)-1 > aspects.index(aspect):\n",
    "                a_i = [i for i,val in enumerate(row[' text']) if val==aspect]\n",
    "                #print(a_i)\n",
    "                \n",
    "                for a_id in a_i:\n",
    "                    try:\n",
    "                        if row[' text'][a_id+1] != aspects[aspects.index(aspect)+1]:\n",
    "                            a_i.remove(a_id)\n",
    "                    except:\n",
    "#                         print('a_i',a_i)\n",
    "#                         print('a_id',a_id)\n",
    "#                         print(a_i.index(a_id))\n",
    "                        a_i = a_i[:a_i.index(a_id)+1]\n",
    "#                         print('exception', a_i)\n",
    "                        break;\n",
    "    #             index.append(row[' text'].index(aspect))\n",
    "                index.extend(a_i)\n",
    "                #print(index)\n",
    "                for i in index:\n",
    "                    p[i] = s_len\n",
    "            else:\n",
    "                index.append(row[' text'].index(aspect))\n",
    "                p[row[' text'].index(aspect)] = s_len\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        for i in range(index[0]):\n",
    "#             p[i] = index[0] - i\n",
    "            p[i] = s_len - index[0] + i\n",
    "        v = s_len\n",
    "        for i in range(index[len(index)-1],len(p)):\n",
    "            #p[i] = i - index[len(index)-1]\n",
    "            if i == index[len(index)-1]:\n",
    "                p[i] = v\n",
    "            else:    \n",
    "                p[i] = v - 1\n",
    "                v = v-1\n",
    "            \n",
    "        #print(p)\n",
    "    except Exception as e: \n",
    "#         print(e)\n",
    "#         print(p)\n",
    "#         print('exception caught')\n",
    "#         print('%s,%s'%(row[' text'],row[' aspect_term']))\n",
    "        p = [0 for i in row[' text']]\n",
    "#         print(p)\n",
    "    #print(source_loc_data)\n",
    "    source_loc_data.append(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "def get_pos(row):\n",
    "    index = []\n",
    "    s_len = len(row[' text'])-1\n",
    "    p = row[' text'].copy()\n",
    "    #print('%s in %s: '%(row[' aspect_term'],row[' text']))\n",
    "    aspects = row[' aspect_term'].split(' ')\n",
    "    for aspect in aspects:\n",
    "        try:\n",
    "            if len(aspects)-1 > aspects.index(aspect):\n",
    "                a_i = [i for i,val in enumerate(row[' text']) if val==aspect]\n",
    "                try:\n",
    "                    for a_id in a_i:\n",
    "                        if row[' text'][a_id+1] != aspects[aspects.index(aspect)+1]:\n",
    "                            a_i.remove(a_id)\n",
    "                except:\n",
    "                    pass\n",
    "    #             index.append(row[' text'].index(aspect))\n",
    "                index.extend(a_i[0])\n",
    "            else:\n",
    "                index.append(row[' text'].index(aspect))\n",
    "            p[row[' text'].index(aspect)] = s_len\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        for i in range(index[0]):\n",
    "#             p[i] = index[0] - i\n",
    "            p[i] = s_len - index[0] + i\n",
    "        v = s_len\n",
    "        for i in range(index[len(index)-1],len(p)):\n",
    "            #p[i] = i - index[len(index)-1]\n",
    "            if i == index[len(index)-1]:\n",
    "                p[i] = v\n",
    "            else:    \n",
    "                p[i] = v - 1\n",
    "                v = v-1\n",
    "            \n",
    "        #print(p)\n",
    "    except Exception as e: \n",
    "#         print(e)\n",
    "#         print(p)\n",
    "#         print('exception caught')\n",
    "#         print('%s,%s'%(row[' text'],row[' aspect_term']))\n",
    "        p = [0 for i in row[' text']]\n",
    "#         print(p)\n",
    "    source_loc_data.append(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "def create_vocab(data_train_1):\n",
    "    source_word2idx = {'<pad>': 0}\n",
    "    target_word2idx = {}\n",
    "    for words in data_train_1[' text']:\n",
    "        for word in words:\n",
    "            if word not in source_word2idx:\n",
    "                source_word2idx[word] = len(source_word2idx)\n",
    "\n",
    "    for words in data_train_1[' aspect_term']:\n",
    "        if words not in target_word2idx:\n",
    "            target_word2idx[words] = len(target_word2idx)\n",
    "    return source_word2idx, target_word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data_2_train.csv'\n",
    "#train_file = 'data/data_2_train.csv'\n",
    "\n",
    "data = read_data(train_file)\n",
    "parsed_data = parse_data(data)\n",
    "source_word2idx, target_word2idx = create_vocab(parsed_data)\n",
    "\n",
    "#trainData, testData = process_data.split_data(parsed_data, 80, 20)\n",
    "train_data = read_and_process_data(parsed_data, source_word2idx, target_word2idx)\n",
    "#test_data = process_data.read_and_process_data(testData, source_word2idx, target_word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sen_max_len:  70\n",
      "(3602, 3, 70)\n",
      "(3602, 210)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x1_list, x2_list, x3_list = list(), list(), list()\n",
    "example_list = list()\n",
    "\n",
    "sen_max_len = train_data[4]\n",
    "print(\"sen_max_len: \",sen_max_len)\n",
    "\n",
    "for i in range(len(train_data[0])):\n",
    "    x1, x2, x3 = list(), list(), list()\n",
    "    \n",
    "    x1.extend(train_data[0][i])\n",
    "    if len(x1) < sen_max_len:\n",
    "        for _ in range(sen_max_len - len(x1)):\n",
    "            x1.append(0)\n",
    "    \n",
    "    x2.extend(train_data[1][i])\n",
    "    if len(x2) < sen_max_len:\n",
    "        for _ in range(sen_max_len - len(x2)):\n",
    "            x2.append(0)\n",
    "            \n",
    "    x3.extend(train_data[2][i])\n",
    "    for j in range(len(x1) - 1):\n",
    "        x3.append(x3[0])\n",
    "    for k in range(sen_max_len - len(x3)):\n",
    "        x3.append(0)\n",
    "    \n",
    "    example = list()\n",
    "    example.append(x1)\n",
    "    example.append(x2)\n",
    "    example.append(x3)\n",
    "    #print(\"example: \",example)\n",
    "    example_list.append(example)\n",
    "\n",
    "len(example_list)\n",
    "\n",
    "final_array = np.array(example_list)\n",
    "print(final_array.shape)\n",
    "\n",
    "nsamples, nx, ny = final_array.shape\n",
    "feature_vector = final_array.reshape((nsamples,nx*ny))\n",
    "print(feature_vector.shape)\n",
    "labels = train_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1    2    3 ...    0    0    0]\n",
      " [   7    9   10 ...    1    1    1]\n",
      " [   2   15   29 ...    1    1    1]\n",
      " ...\n",
      " [1777  319  126 ...  342  342  342]\n",
      " [1777  319  126 ...  216  216  216]\n",
      " [1777  319  126 ... 1190 1190 1190]]\n"
     ]
    }
   ],
   "source": [
    "print(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3602"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([805, 2164, 633])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels).keys() # equals to list(set(words))\n",
    "# counts the elements' frequency\n",
    "Counter(labels).values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\tanu\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\tanu\\anaconda3\\lib\\site-packages (from imblearn) (0.9.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in c:\\users\\tanu\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\tanu\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.20.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tanu\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\tanu\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\tanu\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1, 2164), (0, 2164), (1, 2164)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(feature_vector, labels)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5193, 210)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1731, 1730, 1732])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train_labels).keys() # equals to list(set(words))\n",
    "# counts the elements' frequency\n",
    "Counter(train_labels).values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#print(train_vectors.shape)\n",
    "#print(train_labels.shape)\n",
    "#print(test_vectors.shape)\n",
    "#print(test_labels.shape)\n",
    "print(type(train_vectors))\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "X = train_vectors\n",
    "y = train_labels\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "#print(\"Feature ranking:\")\n",
    "\n",
    "# for f in range(X.shape[1]):\n",
    "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5193, 50)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.shape\n",
    "train_vectors.shape[0]\n",
    "train_X = np.zeros(shape=(train_vectors.shape[0],50))\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RFR: \n",
      "\n",
      "scores:  [0.73269231 0.72115385 0.79807692 0.75337187 0.80732177 0.79576108\n",
      " 0.77071291 0.75529865 0.7495183  0.76300578]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.74      0.76       433\n",
      "           0       0.79      0.84      0.82       432\n",
      "           1       0.76      0.76      0.76       434\n",
      "\n",
      "    accuracy                           0.78      1299\n",
      "   macro avg       0.78      0.78      0.78      1299\n",
      "weighted avg       0.78      0.78      0.78      1299\n",
      "\n",
      "Overall accuracy:  0.7806004618937644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFR\n",
    "#10,20,50,80\n",
    "n_estimators = [100,200,500]\n",
    "rfr = RFR(n_estimators=100,random_state=0)\n",
    "\n",
    "print(\"Results for RFR: \")\n",
    "print()\n",
    "\n",
    "rfr_scores = cross_val_score(rfr, train_vectors, train_labels, cv=10)  \n",
    "print('scores: ', rfr_scores)\n",
    "\n",
    "rfr.fit(train_vectors,train_labels)\n",
    "y_pred = rfr.predict(test_vectors) \n",
    "\n",
    "rfr_accuracy = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Overall accuracy: \",rfr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for DecisionTreeClassifier: \n",
      "\n",
      "scores:  [0.73269231 0.72115385 0.79807692 0.75337187 0.80732177 0.79576108\n",
      " 0.77071291 0.75529865 0.7495183  0.76300578]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.65      0.64       433\n",
      "           0       0.65      0.64      0.64       432\n",
      "           1       0.67      0.65      0.66       434\n",
      "\n",
      "    accuracy                           0.65      1299\n",
      "   macro avg       0.65      0.65      0.65      1299\n",
      "weighted avg       0.65      0.65      0.65      1299\n",
      "\n",
      "Overall accuracy:  0.648960739030023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,random_state=0)\n",
    "print(\"Results for DecisionTreeClassifier: \")\n",
    "print()\n",
    "rfr_scores = cross_val_score(rfr, train_vectors, train_labels, cv=10)  \n",
    "print('scores: ', rfr_scores)\n",
    "\n",
    "dt_clf.fit(train_vectors,train_labels)\n",
    "y_pred = dt_clf.predict(test_vectors)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "print(\"\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Overall accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  [0.66730769 0.66538462 0.68076923 0.6955684  0.69171484 0.70134875\n",
      " 0.66859345 0.66859345 0.65317919 0.68208092]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.77      0.72       433\n",
      "           0       0.66      0.90      0.76       432\n",
      "           1       0.77      0.38      0.51       434\n",
      "\n",
      "    accuracy                           0.68      1299\n",
      "   macro avg       0.70      0.68      0.66      1299\n",
      "weighted avg       0.70      0.68      0.66      1299\n",
      "\n",
      "Overall accuracy:  0.6828329484218629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "scores = cross_val_score(knn, train_vectors, train_labels, cv=10)  \n",
    "print('scores: ', scores)\n",
    "\n",
    "knn.fit(train_vectors, train_labels)\n",
    "y_pred = knn.predict(test_vectors)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "print(\"\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Overall accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  [0.83349374 0.8479307  0.81905679 0.8479307  0.83060635 0.82964389\n",
      " 0.84023099 0.82466281 0.85067437 0.83911368]\n",
      "classifier_svc_accuracy:  0.8502117828263381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.83      0.88       922\n",
      "           0       0.84      0.89      0.87       887\n",
      "           1       0.78      0.83      0.80       788\n",
      "\n",
      "    accuracy                           0.85      2597\n",
      "   macro avg       0.85      0.85      0.85      2597\n",
      "weighted avg       0.85      0.85      0.85      2597\n",
      "\n",
      "Overall accuracy:  0.8502117828263381\n"
     ]
    }
   ],
   "source": [
    "svc_classifier = svm.SVC(C = 100)\n",
    "\n",
    "classifier_svc_scores = cross_val_score(svc_classifier, train_vectors, train_labels, cv=10)  \n",
    "print('scores: ', classifier_svc_scores)\n",
    "\n",
    "svc_classifier.fit(train_vectors, train_labels)\n",
    "prediction_svc = svc_classifier.predict(test_vectors)\n",
    "\n",
    "classifier_svc_accuracy = accuracy_score(test_labels, prediction_svc)\n",
    "print('classifier_svc_accuracy: ', classifier_svc_accuracy)\n",
    "\n",
    "print(\"\")\n",
    "print(classification_report(test_labels, prediction_svc))\n",
    "print(\"Overall accuracy: \",classifier_svc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9557181363111282\n",
      "0.9457065845206007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('rfr', rfr), ('knn', knn), ('dt_clf', dt_clf)], voting='hard')\n",
    "eclf1 = eclf1.fit(train_vectors, train_labels)\n",
    "eclf1_pred = eclf1.predict(test_vectors)\n",
    "eclf1_accuracy_score = accuracy_score(test_labels, eclf1_pred)\n",
    "print(eclf1_accuracy_score)\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('rfr', rfr), ('knn', knn), ('dt_clf', dt_clf)], voting='soft')\n",
    "eclf2 = eclf2.fit(train_vectors, train_labels)\n",
    "eclf2_pred = eclf2.predict(test_vectors)\n",
    "eclf2_accuracy_score = accuracy_score(test_labels, eclf2_pred)\n",
    "print(eclf2_accuracy_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
